---
title: "Code Sample"
author: "Seth Harrison"
date: "05/03/2020"
output: github_document
---

```{r setup, include=FALSE}

library(caret)
library(tidyverse)
library(readr)
library(tidytext)
library(tm)
library(ranger)
library(e1071)
library(dplyr)
library(ranger)
library(corpus)

```


# Tidy Data

```{r, message=FALSE,warning=FALSE}

Data <- read_csv("SyriaData.csv") %>%
        select(c(1,5,8,9)) %>%
        na.omit()

stop_words <- read_lines("ARstopwords") %>%
              as_data_frame()

stop_words <- rename(stop_words, text = value)

tokens <- Data %>%
   unnest_tokens(output = text, input = text) %>%
   # remove stop words
   anti_join(stop_words) %>%
   # stem the words
   corpus::as_corpus_frame() %>%
   mutate(word = corpus::text_tokens(text, stemmer = "ar"))

tokens$word <- as.character(tokens$word)

```

# Create Document-Term Matrix

```{r, message=FALSE, warning=FALSE}

dtm <- tokens %>%
   # get count of each token in each document
   count(id, word) %>%
   # create a document-term matrix with all features and term frequency inverse document frequency 
   cast_dtm(document = id, term = word, value = n, weighting = tm::weightTfIdf)

  # remove sparse terms
dtm <- removeSparseTerms(dtm, sparse = .99)

```

# Estimate model

```{r, message=FALSE, warning=FALSE}

slice <- slice(Data, 1:614)

rf <- train(x = as.matrix(dtm),
                     y = factor(slice$classification),
                     method = "ranger",
                     num.trees = 200,
                     importance = "impurity",
                     trControl = trainControl(method = "oob"))

rf$finalModel

```

 